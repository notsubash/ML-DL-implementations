{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/subashpandey/Desktop/ML-DL-From-Scratch/data/'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(root=image_path, train=True, transform=transform, download=False)\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, train=False, transform=transform, download=False)\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [32,16]\n",
    "image_size = mnist_train_dataset[0][0].shape\n",
    "input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "all_layers = [nn.Flatten()]\n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "model = nn.Sequential(*all_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model starts with a flatten layer that flattens an input image into\n",
    "a one-dimensional tensor. This is because the input images are in the shape of\n",
    "[1, 28, 28]. The model has two hidden layers, with 32 and 16 units respectively.\n",
    "And it ends with an output layer of ten units representing ten classes, activated\n",
    "by a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Accuracy 0.8531\n",
      "Epoch 1  Accuracy 0.9287\n",
      "Epoch 2  Accuracy 0.9413\n",
      "Epoch 3  Accuracy 0.9506\n",
      "Epoch 4  Accuracy 0.9558\n",
      "Epoch 5  Accuracy 0.9592\n",
      "Epoch 6  Accuracy 0.9627\n",
      "Epoch 7  Accuracy 0.9649\n",
      "Epoch 8  Accuracy 0.9673\n",
      "Epoch 9  Accuracy 0.9690\n",
      "Epoch 10  Accuracy 0.9711\n",
      "Epoch 11  Accuracy 0.9729\n",
      "Epoch 12  Accuracy 0.9737\n",
      "Epoch 13  Accuracy 0.9747\n",
      "Epoch 14  Accuracy 0.9766\n",
      "Epoch 15  Accuracy 0.9778\n",
      "Epoch 16  Accuracy 0.9780\n",
      "Epoch 17  Accuracy 0.9798\n",
      "Epoch 18  Accuracy 0.9807\n",
      "Epoch 19  Accuracy 0.9815\n"
     ]
    }
   ],
   "source": [
    "# training, evaluation, and prediction\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "        accuracy_hist_train += is_correct.sum()\n",
    "    accuracy_hist_train /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch}  Accuracy '\n",
    "          f'{accuracy_hist_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9647\n"
     ]
    }
   ],
   "source": [
    "pred = model(mnist_test_dataset.data / 255.)\n",
    "is_correct = (torch.argmax(pred, dim=1) == mnist_test_dataset.targets).float()\n",
    "print(f\"Test accuracy: {is_correct.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subash-pandey-jvfq-machine-learning-new-vz-Rrc3MWra-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
