{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112310\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "## Reading and processing text\n",
    "with open('1268-0.txt', 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most NN libraries and RNN implementations cannot deal\n",
    "with input data in string format, which is why we have to convert the text into a numeric format. To do\n",
    "this, we will create a simple Python dictionary that maps each character to an integer, char2int. We\n",
    "will also need a reverse mapping to convert the results of our model back to text. Although the reverse\n",
    "can be done using a dictionary that associates integer keys with character values, using a NumPy array\n",
    "and indexing the array to map indices to those unique characters is more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1112310,)\n",
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n",
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n",
      "48 -> Y\n",
      "43 -> S\n",
      "44 -> T\n",
      "29 -> E\n",
      "42 -> R\n",
      "33 -> I\n",
      "39 -> O\n",
      "45 -> U\n",
      "43 -> S\n",
      "1 ->  \n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32\n",
    ")\n",
    "print('Text encoded shape:', text_encoded.shape)\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(text_encoded[15:21], '== Reverse ==>',\n",
    "      ''.join(char_array[text_encoded[15:21]]))\n",
    "for ex in text_encoded[:15]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length+1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded) - chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/_8jmmysn22sbx4zjv3c2lm980000gn/T/ipykernel_7073/1165515296.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text_chunk = self.text_chunks[index]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x):  'THE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n1'\n",
      " Target (y):  'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      "\n",
      " Input (x):  'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      " Target (y):  'E MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n187'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(' Input (x): ',\n",
    "          repr(''.join(char_array[seq])))\n",
    "    print(' Target (y): ',\n",
    "          repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subashpandey/Library/Caches/pypoetry/virtualenvs/subash-pandey-jvfq-machine-learning-new-vz-Rrc3MWra-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.3720\n",
      "Epoch 500 loss: 1.5593\n",
      "Epoch 1000 loss: 1.3769\n",
      "Epoch 1500 loss: 1.3498\n",
      "Epoch 2000 loss: 1.2374\n",
      "Epoch 2500 loss: 1.1918\n",
      "Epoch 3000 loss: 1.1465\n",
      "Epoch 3500 loss: 1.1611\n",
      "Epoch 4000 loss: 1.0998\n",
      "Epoch 4500 loss: 1.1116\n",
      "Epoch 5000 loss: 1.0913\n",
      "Epoch 5500 loss: 1.0913\n",
      "Epoch 6000 loss: 1.0623\n",
      "Epoch 6500 loss: 1.0994\n",
      "Epoch 7000 loss: 1.0379\n",
      "Epoch 7500 loss: 1.0502\n",
      "Epoch 8000 loss: 1.0503\n",
      "Epoch 8500 loss: 1.0589\n",
      "Epoch 9000 loss: 1.0437\n",
      "Epoch 9500 loss: 1.0398\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor(\n",
    "        [char2int[s] for s in starting_str]\n",
    "    )\n",
    "    encoded_input = torch.reshape(\n",
    "        encoded_input, (1, -1)\n",
    "    )\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(\n",
    "            encoded_input[:, c].view(1), hidden, cell\n",
    "        )\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(\n",
    "            last_char.view(1), hidden, cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits = scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island hope to\n",
      "make Tabor Island. A few rays!” cried Pencroft, “for besides, promised to be made from the\n",
      "highest be severely that he carefully examined, but they could not have gineous, till thinking thumself over.\n",
      "\n",
      "Pencroft knew more escaped from the question. You saw\n",
      "Jup, but sometimes continued. He was then sheltered the position\n",
      "of the monkeys moss a more masoned drink.\n",
      "\n",
      "“What are the entrance from the crater east!” exclaimed the engineer, “if it has been able to south, for it was still nothing b\n"
     ]
    }
   ],
   "source": [
    "# generating some new text\n",
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698605]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611686]\n",
      "Probabilities after scaling with 0.1: [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "source": [
    "# importance of scale factor\n",
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', nn.functional.softmax(0.5*logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', nn.functional.softmax(0.1*logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was there that the bed of the sea, and in a voice was not wanting for the forest, bounding over the island.\n",
      "\n",
      "The colonists should disturb his life, and the colonists had not been torn with the tide was there. Neb and Pencroft had become carefully explored the shore, the box was in sight of the balloon was composed of the colony, soon made a magnificent trees, and which flows were the narrow gallinaceae, which was not more than two years and the manufacture of the lake would perhaps\n",
      "many very fa\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island fougred, He treuml at Grotto amour,\n",
      "throwed off enemy, caft which done some issueable dograe, built infffliently Neved\n",
      "that his hode hard impelled,” but\n",
      "yetcedluge.”\n",
      "\n",
      "“Oh, Wasomak picict-insue!\n",
      "\n",
      "Tubeltileasings, 5chee lying! ourse, Nez 90 Oyrusua--drip?\n",
      "Mr!-\n",
      "Washed the replain,” answered Neb.\n",
      "\n",
      "That moment he azid feared burst roasted, Pencroft.?\n",
      "errates,”\n",
      "squee drwited from\n",
      "damp pet!’\n",
      "\n",
      "Chaneay Housa--jeaced Tabor Would ventured every destruarized mmethrubsions;, our mountain wide, and novclo,--\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subash-pandey-jvfq-machine-learning-new-vz-Rrc3MWra-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
